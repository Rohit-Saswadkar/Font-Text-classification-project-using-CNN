{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMGwn1IMw+ES3Jgt+19iAG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit-Saswadkar/Font-Text-classification-project-using-CNN/blob/main/1%5D_Model_development_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Font Recognition Model Architecture using CNN"
      ],
      "metadata": {
        "id": "MjD007MhYouO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**by Rohit Saswadkar**\n",
        "* Email - rohit.saswadkar1@gmail.com\n",
        "* Linkedin - linkedin.com/in/rohit-saswadkar-595453237\n",
        "* Project Link - https://github.com/Rohit-Saswadkar/Font-Text-classification-project-using-CNN/tree/main\\\n",
        "* Dataset download link - https://www.kaggle.com/datasets/muhammadardiputra/font-recognition-data/download?datasetVersionNumber=1\n",
        "* Dataset website - https://www.kaggle.com/datasets/muhammadardiputra/font-recognition-data"
      ],
      "metadata": {
        "id": "hNrIw6wYYsSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Advancements**"
      ],
      "metadata": {
        "id": "3ILO_Xa_wJ0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Added padding to the images and maintained aspect ratio\n",
        "2. Applied Gaussin blur to reduce noise and add smoother boundaries\n",
        "3. Data Augmentation techniques\n",
        "4. Improved Model Architecture\n",
        "5. Early stoppin while training\n",
        "\n",
        "**This techniques are explained at each implementation stage.**"
      ],
      "metadata": {
        "id": "kvkL1WQEwN36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required libraries\n",
        "1] tensorflow to create a model\n",
        "2] open cv for image processing"
      ],
      "metadata": {
        "id": "Kbpr3MQO4o6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install cv2"
      ],
      "metadata": {
        "id": "Gzvj_wP7o-cu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7a2c09-c96b-4a00-b239-fb09e40a2471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y4hAIKdog5W",
        "outputId": "03938b4d-62a6-4e0c-8dd5-9e1924afc620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1] Import required libraries**"
      ],
      "metadata": {
        "id": "QTfluBogZhqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vX5y-vbt1QD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_width = 128\n",
        "image_height = 32"
      ],
      "metadata": {
        "id": "Qr42FH7TYBSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2] Download the dataset from the provided link and paste the file path below to begin the training process.**\n",
        "* There are 2 Datasets 1] Font dataset large and 2] Font dataset large color.\n",
        "* I trained on Font dataset large (gray scale) to reduce computation load on system. Load that \"Font dataset large\" datasets in the path"
      ],
      "metadata": {
        "id": "ok1nm308Z5M1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the font dataset\n",
        "path = r\"/content/drive/MyDrive/Data Science Advanced Projects/1 Data Science Advanced/Deep learning/Font recognition assessment/New Data/New Start\""
      ],
      "metadata": {
        "id": "3C3wXEKW1Lmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Ingestion**"
      ],
      "metadata": {
        "id": "_tFI8MMQaCBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3] This function loads font images and their corresponding labels from the specified directory. It get input as dictionary , extracts the images and its corresponding labels and stores this into images and labels lists.\n",
        "\n",
        "* I used cv2 to convert the color images to grayscale as we have to only text classification ( also it reduce the computationl load on the laptop). we can also train the model using color data as we have to only remove the line number 1] as shown in below\n"
      ],
      "metadata": {
        "id": "ElR9bMwZa3zW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Improvements:**\n",
        "* Added Gaussian blur which will reduce the noise in the image and smoothens the boundaries which make the model robust and genralize well on unseen data\n",
        "\n",
        "*  Converted all image in the size of 32 x 128 while maintaining Aspect ratio as the images in our dataset arent of uniform size so I mainrtained their aspect ration and resized to 32x 128 which will balance the short and long words of the dataset.\n",
        "\n",
        "* For this I use open cv to add padding and added 255 in those padded pixel as it will introduce white background to all images"
      ],
      "metadata": {
        "id": "hQOxr7bsY4f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_directory, target_height=32, target_width=128, apply_gaussian_blur=True):\n",
        "    images = []\n",
        "    labels = []\n",
        "    font_names = os.listdir(data_directory)\n",
        "    for font_name in font_names:\n",
        "        font_dir = os.path.join(data_directory, font_name)\n",
        "        for image_name in os.listdir(font_dir):\n",
        "            image_path = os.path.join(font_dir, image_name)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Apply Gaussian blur if specified\n",
        "            if apply_gaussian_blur:\n",
        "                image = cv2.GaussianBlur(image, (5, 5), 0)  # -------------------Applied gaussian blur which will reduce the noise and improve generalization\n",
        "\n",
        "            # Convert to grayscale if input is any color image\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # ------------------ 1] Conerted all images to grayscale as our images has 3 channels\n",
        "\n",
        "            # Resize image while preserving aspect ratio\n",
        "            h, w = image.shape\n",
        "            aspect_ratio = w / h\n",
        "            if aspect_ratio < (target_width / target_height):\n",
        "                new_width = int(target_height * aspect_ratio)\n",
        "                resized_image = cv2.resize(image, (new_width, target_height))\n",
        "                pad_left = (target_width - new_width) // 2\n",
        "                pad_right = target_width - new_width - pad_left\n",
        "                resized_image = cv2.copyMakeBorder(resized_image, 0, 0, pad_left, pad_right, cv2.BORDER_CONSTANT, value= 255)\n",
        "            else:\n",
        "                new_height = int(target_width / aspect_ratio)\n",
        "                resized_image = cv2.resize(image, (target_width, new_height))\n",
        "                pad_top = (target_height - new_height) // 2\n",
        "                pad_bottom = target_height - new_height - pad_top\n",
        "                resized_image = cv2.copyMakeBorder(resized_image, pad_top, pad_bottom, 0, 0, cv2.BORDER_CONSTANT, value= 255)\n",
        "\n",
        "            images.append(resized_image)\n",
        "            labels.append(font_name)\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "id": "FEQt_wOy1SiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = path\n",
        "images, labels = load_data(data_directory)"
      ],
      "metadata": {
        "id": "xnx-2_eg1Wec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nDataset shape:', images.shape)\n",
        "\n",
        "print('Labels of the dataset:',set(labels))"
      ],
      "metadata": {
        "id": "UVx4j_WmVbDX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8310e701-b556-4148-aaf7-9585581fc3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset shape: (11952, 32, 128)\n",
            "Labels of the dataset: {'Century', 'Times New Roman', 'Calibry', 'Arial', 'Georgia', 'Verdana'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4] Applied one hot encoding on the labels as we have multiple classes**"
      ],
      "metadata": {
        "id": "Ji6pJv6ZZT7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding\n",
        "label_to_index = {label: i for i, label in enumerate(np.unique(labels))}\n",
        "index_to_label = {i: label for label, i in label_to_index.items()}\n",
        "labels_encoded = np.array([label_to_index[label] for label in labels])\n",
        "labels_one_hot = tf.keras.utils.to_categorical(labels_encoded)"
      ],
      "metadata": {
        "id": "mYIGMpIQ1YvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5] This code snippet splits the dataset into training, validation, and test sets using the train_test_split function.**"
      ],
      "metadata": {
        "id": "szqaWsDHa78R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels_one_hot, test_size=0.2, random_state=42, stratify=labels_one_hot)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
      ],
      "metadata": {
        "id": "M37DH56W1aZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6] This code preprocesses the data by normalizing pixel values and reshaping the input data to match the CNN input shape.**\n",
        "\n",
        "* Each value in matrix of an image represents the color range from 0 to 255 so\n",
        " I Normalized the values of each image by dividing by 255 to convert them in the range of 0 to 1."
      ],
      "metadata": {
        "id": "9l0OQ3zcbFk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the data (normalize pixel values)\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_val = X_val.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# reshape data to match the input shape of the CNN\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)"
      ],
      "metadata": {
        "id": "NB0uysv01i1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Augmentation:**\n",
        "\n",
        "* It rotates the image by -15 to 15 degree\n",
        "* Also does width shift and heigt shifts by 10%\n",
        "* It zooms the image by 20 % and Zoomout by 20%\n",
        "* After all transformations the newly created pixels are filled by nearest pixels"
      ],
      "metadata": {
        "id": "DBeS9xNcbvw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data augmentation parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "ohUurCxIUP95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The Geneartor genrates the augmented images as well as normal images on the fly ith batch size of 32 images to the model"
      ],
      "metadata": {
        "id": "WPO4YIHRfPM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generators for training and validation\n",
        "train_data_generator = datagen.flow(X_train, y_train, batch_size=32)\n",
        "val_data_generator = datagen.flow(X_val, y_val, batch_size=32)"
      ],
      "metadata": {
        "id": "bvL05GE-URy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model architecture**\n",
        "\n",
        "* 1] in this I created 32 filters as of size 3 * 3 and slides along the image to extract meaninful features.\n",
        "\n",
        "* 2] I used max pooling to extract the most valuable features by size of 2 * 2 to minimize computation and reduce overfitting.\n",
        "\n",
        "*  I used relu as activation function in hidden layer to introduce non linearity in the model which returns values if its positive else returns 0 if the vlues is negative.\n",
        "\n",
        "* 3] Used Flatten layer as it flattens the input matrix into 1d array\n",
        "\n",
        "* 4] I Created dense layers of 64 neurons to reduce computational power as I trained this model in my laptop and also it reduces overfitting.\n",
        "\n",
        "* 5] I used softmax in output layer as its mostly used for classification tasks. it converts raw inputs to the probabilities of the classes.\n"
      ],
      "metadata": {
        "id": "oP2QQCJya-wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advancements in architecture-**\n",
        "* 1]  Added the zero padding in each convolutional layer in all Convolutional layers.\n",
        "* 2] Added kernel initializer Xavier initializer using \"glorot uniform\"\n",
        "* 3] Added Batch normalization which will normalize the output of the cnn layers effects faster generalization of the model.\n",
        "* 2] Added 50% dropout neuron layer after each hidden layer.\n",
        "* 3] Added Extra hidden layer of 64 neurons."
      ],
      "metadata": {
        "id": "ofw1fbqRxgOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), padding='same', input_shape=(image_height, image_width , 1), kernel_initializer='glorot_uniform'),\n",
        "    layers.BatchNormalization(),  # Batch normalization added here\n",
        "    layers.LeakyReLU(alpha=0.1),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='glorot_uniform'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.1),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='glorot_uniform'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.1),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, kernel_initializer='glorot_uniform'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.1),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(64, kernel_initializer='glorot_uniform'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.LeakyReLU(alpha=0.1),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(label_to_index), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "9CgqArAa1ejR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7] This code snippet compiles the CNN model with the specified optimizer, loss function, and metrics.**\n",
        "\n",
        "* Used adam as learning to adjust the weights during each epochs as its robust to sparse or noisy gradients.\n",
        "\n",
        "* I used categorical crossentropy as i applied one hot encoding on labels else we have to use sparse categoruical cross entropy.\n",
        "\n",
        "* Used Accuracy as performance monitoring metrics during training as our classification task."
      ],
      "metadata": {
        "id": "0Qdx7yTqbCMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "riVrkO2n1gxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8] Early stopping**\n",
        "* It stops the training when the change in loss is almost stoppd.\n",
        "* It waits for change in validation loss upto 3 epochs.\n",
        "* Finally it restores best performing weights on the validation set."
      ],
      "metadata": {
        "id": "nVaP4ftEwBp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "nhlAjEM8U1F_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9] This code snippet trains the CNN model on the training data and validates it on the validation data.**\n",
        "\n",
        "* I applied 10 epochs to reduce computational load. (It took 2 hours to train the model on entire 153600 images).\n",
        "* steps per epochs enssures that the all images of the train dataset should be trained even if they arent complitely divisible by 32"
      ],
      "metadata": {
        "id": "pEq4O_c913Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data_generator,\n",
        "          steps_per_epoch=len(X_train) // 32,\n",
        "          epochs=10,  #---------------------------------- increase the number of epochs to allow for early stopping\n",
        "          validation_data=val_data_generator,\n",
        "          validation_steps=len(X_val) // 32,\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "aKM64eaT1jhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d792b4d6-7e14-480d-9d64-8545cb0dcd1e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "239/239 [==============================] - 103s 431ms/step - loss: 0.7397 - accuracy: 0.6704 - val_loss: 5.7052 - val_accuracy: 0.2595\n",
            "Epoch 2/10\n",
            "239/239 [==============================] - 100s 417ms/step - loss: 0.7129 - accuracy: 0.6889 - val_loss: 6.9650 - val_accuracy: 0.3109\n",
            "Epoch 3/10\n",
            "239/239 [==============================] - 97s 404ms/step - loss: 0.6633 - accuracy: 0.7152 - val_loss: 9.0149 - val_accuracy: 0.3867\n",
            "Epoch 4/10\n",
            "239/239 [==============================] - 93s 387ms/step - loss: 0.6568 - accuracy: 0.7204 - val_loss: 1.6229 - val_accuracy: 0.4815\n",
            "Epoch 5/10\n",
            "239/239 [==============================] - 95s 398ms/step - loss: 0.6199 - accuracy: 0.7394 - val_loss: 5.2250 - val_accuracy: 0.2352\n",
            "Epoch 6/10\n",
            "239/239 [==============================] - 97s 405ms/step - loss: 0.5790 - accuracy: 0.7586 - val_loss: 9.6654 - val_accuracy: 0.2680\n",
            "Epoch 7/10\n",
            "239/239 [==============================] - 94s 393ms/step - loss: 0.5695 - accuracy: 0.7592 - val_loss: 1.1108 - val_accuracy: 0.6017\n",
            "Epoch 8/10\n",
            "239/239 [==============================] - 96s 401ms/step - loss: 0.5646 - accuracy: 0.7663 - val_loss: 1.2099 - val_accuracy: 0.5286\n",
            "Epoch 9/10\n",
            "239/239 [==============================] - 99s 414ms/step - loss: 0.5673 - accuracy: 0.7667 - val_loss: 3.9106 - val_accuracy: 0.3305\n",
            "Epoch 10/10\n",
            "239/239 [==============================] - 96s 399ms/step - loss: 0.5376 - accuracy: 0.7752 - val_loss: 0.9342 - val_accuracy: 0.6457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's accuracy on the training data is increasing, indicating successful learning. However, fluctuations in validation accuracy suggest the model might be overfitting to the training data. This could be due to model is too complex or lack of regularization."
      ],
      "metadata": {
        "id": "yKZsbGLTiyxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Evaluation**"
      ],
      "metadata": {
        "id": "4ZWNAnU710qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluates the model on test data and gets accuracvy\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "YWHrsSt-1jmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluates the model on validation data and gets accuracvy\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "print(\"Validation Accuracy:\", val_accuracy)"
      ],
      "metadata": {
        "id": "9r4QwQa31jjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing accuracy values\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plotting accuracy vs epochs\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Accuracy vs Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UD1Kd33iWyfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Visualize confusion matrix\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_to_index.keys(), yticklabels=label_to_index.keys())\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1AEB1S4lKPiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9] Save the model at specified path**"
      ],
      "metadata": {
        "id": "LEp1bDVhbmXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path eto save the model\n",
        "path2 = r\"/content/drive/MyDrive/Data Science Advanced Projects/1 Data Science Advanced/Deep learning/Font recognition assessment/New Data\"\n",
        "\n",
        "model.save(path + 'font_recognition_model_large_model_3.h5')"
      ],
      "metadata": {
        "id": "HV_GF1xmxkps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc87933-feea-4444-ba85-08b9ba013004"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Conclusion -**"
      ],
      "metadata": {
        "id": "IPSJrSRGiM5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Challenges -**\n",
        "\n",
        "1. Model performance on train data is improving while on validation data its flactuating means model struggles to perform on unseen data and its underlying the overfitting problem.\n",
        "\n",
        "2. Model loss changing slowly could be due to vanishing gradients or the learning rate is too small.\n",
        "\n",
        "3. This could stem from factors such as model complexity or a learning rate that is too low, causing the model struggle with convergence.\n",
        "\n",
        "**Solutoins -**\n",
        "1. Hyperaparmeter tuning with activation functions, batch size,dropout nerons can lead to a better generalised model.\n",
        "\n",
        "2. Regularization techniques such L2 regularization also can helpful.\n",
        "\n",
        "3. Hyperparameter tuning with optimization techniques such as adam, stochastic gradient decent, NaG, RMS prop can also increase the performance.\n",
        "\n",
        "4. Reducing model complexity by increasing dropout neurons, less hidden layers"
      ],
      "metadata": {
        "id": "d9Qs0jm6Yu2-"
      }
    }
  ]
}